## Discussion and Conclusions

BioRxiv is a constantly growing repository that contains life science preprints.
The majority of research involving bioRxiv focuses on the metadata of preprints; however, the language contained within these preprints has yet to be systematically examined.
Throughout this work we sought to analyze the language contained within these preprints and understand how it changes in response to peer review.
Through our global corpora analysis, we found that writing within bioRxiv is consistent with the biomedical literature contained in the PMCOA repository, suggesting that bioRxiv is linguistically similar to PMCOA.
Token-level analyses between bioRxiv and PMCOA suggested that major differences are driven by research fields where more patient related research is prevalent in PMCOA than bioRxiv.
This observation is expected as patient preprints are funneled from bioRxiv into the medRxiv repository [@url:https://www.medrxiv.org/].
Token-level analyses for preprints and their corresponding published version suggests that peer review may focus on data availability and incorporating extra sections for published papers; however, future analyses are needed to ascertain individual token level changes as preprints venture through the publication process.

Document embeddings are a versatile way to examine language contained within preprints, understanding peer review's effect on preprints, and provide extra functionality for preprint repositories.
Examining linguistic variance contained within document embeddings of life science preprints revealed that the largest source of variability was informatics vs cellular biology.
This observation bisects majority of life science research as research analysis can be from either or both concept types.
Preprints are typically linked with their published articles via bioRxiv manually establishing a link or authors self-reporting that their preprint has been published; however, gaps can occur as preprints change their appearance through multiple versions or authors do not notify bioRxiv. 
Our work utilized document embeddings to fill in these missing links within bioRxiv, suggesting that these embeddings provide an extensive way to establish preprint-published links.
Furthermore, our analysis suggests that the publication rate for preprints is in fact higher than previously estimated; however, our analysis only accounts for papers that are published open access.
This means our results should only be considered to raise the lower bound of the total preprint publication fraction; however, the true fraction is likely to be much higher.
Future work, especially that which aims to assess the fraction of preprints that are eventually published, should account for the possibility of missed annotations.

Preprints take variable amount of time to become published and our work sought to provide more insight on a preprints time to publication.
Our half-life analysis on preprint categories revealed that majority of categories take the same amount of time for preprints to be published.
Exception towards this trend is the scientific communication and education category, suggesting that some part of the peer review process greatly halts preprints within this category.
In respect to individual preprints, each substantial change adds an additional 16 days for a preprint to become published; however, an additional 51 days are added in cases where a preprint has to have a completely new version constructed.
Future direction would be to examine the types of changes requested by the peer review process that results in long delay times.

Lastly, we found that document embeddings were associated with the eventual journal at which the work was published.
We trained two machine learning models to identify which journals publish linguistically similar papers towards a query preprint.
Our models achieved a considerably higher fold change over the baseline model; however, future models should include more information than solely textual content to improve performance.
Following model training, we constructed a web application that makes our models available to the public and returns a list of the papers and journals that are linguistically similar to a bioRxiv or medRxiv preprint.
