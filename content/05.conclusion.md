## Conclusions

We analyzed the full text of bioRxiv, comparing it with the open access portion of PMC, and found that the overall manner of writing is consistent with the biomedical literature.
A benefit of analyzing bioRxiv text is that we can compare preprint and published versions to examine the influence of the publication process.
Token-level analyses suggest that differences between corpora are driven by fields, while comparisons of preprints with their corresponding publication reveals differences in typesetting and supplementary materials.

Previous analyses have focused on article metadata, including which papers are heavily downloaded and discussed [@doi:10.7554/eLife.45133] and by which communities discuss them [@doi:10.1371/journal.pbio.3000860].
We found that some preprints are highly similar to published articles within the PMC open access corpus, and a detailed examination revealed that many preprints were published but not previously annotated.
Using the full text of documents to correct these missing annotations provides a comprehensive understanding of the extent to which preprints are published and this correction resulted in a publication rate that is higher than previously estimated.
Importantly, this only accounts for papers that are published open access, so our analysis should be considered to raise the lower bound but the truly published fraction is likely to be higher.

Our work presents a first step towards understanding the process by which peer review alters life sciences papers through an analysis of the full text of preprints and their corresponding publication.
Our broad-based examination suggests certain changes, but the scale of changes appears modest.
We lay the groundwork for future work that aims to identify sentences and claims that are altered during review.
Our finding that document embeddings reveal manuscripts with similar outcomes is likely to be important to new tools that accelerate publishing, including those that automatically perform integrity checks and other critically important contributions.
We also found that document embeddings captured many elements of how authors use language in preprints.
Fields were separated first on an informatics / molecular axis, and author-selected categories could be distinguished based on embeddings.
Document embeddings were also associated with the eventual journal at which the work was published.
Based on this observation, we supply a web application that returns the papers and journals that are most similar to a bioRxiv or medRxiv preprint.
