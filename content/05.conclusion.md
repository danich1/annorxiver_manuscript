## Discussion and Conclusions

BioRxiv is a popular repository that contains life science preprints; however, the language contained within these preprints remains unknown.
Throughout this work we sought to analyze the language contained within these preprints and understand how it changes in response to the peer review process.
Through our global corpora analysis, we found that writing within bioRxiv is consistent with the biomedical literature contained in the PMCOA repository, suggesting that bioRxiv is linguistically similar to PMCOA.
Token-level analyses between bioRxiv and PMCOA suggested that major differences are driven by research fields where more patient related research is prevalent in PMCOA than bioRxiv.
This observation is expected as patient preprints are funneled from bioRxiv into the medRxiv repository [@url:https://www.medrxiv.org/].
Through our document embedding approach., we observed that life science preprints were separated on an informatics / molecular axis, suggesting that majority of life science research involves some form of a cellular biology or an informatics type of approach.

Preprints are typically linked with their published articles via bioRxiv manually establishing a link or authors self-reporting that their preprint has been published; however, gaps can occur as preprints change their appearance through multiple versions or authors do not notify bioRxiv. 
We used the full text of documents to correct these missing annotations and our analysis provided a comprehensive understanding of the extent to which preprints are published.
This correction resulted in a publication rate that is higher than previously estimated.
Importantly, our analysis only accounts for papers that are published open access, so these results should be considered to raise the lower bound of the total preprint publication fraction; however, the true fraction is likely to be much higher.
In any case, future work, especially that which aims to assess the fraction of preprints that are eventually published, should account for the possibility of missed annotations.

Our work presents an early step towards understanding the process by which peer review alters life sciences papers.
We analyzed and compared of the full text of preprints with their corresponding publication.
Our analysis revealed differences in typesetting and supplementary materials, suggesting that the majority of peer review changes are modest at best. 
Our results lay out the groundwork for future endeavors that aims to identify sentences and claims that are altered during the peer review process.
Preprints in general take approximately 16 days on average to venture through the peer review process provided that modest changes are requested.
We also discovered that the peer review process is agnostic to preprint categories overall with the exception being the scientific communication and education category.
Future investigation is required to uncover the reasons behind this large delay.

Lastly, we found that document embeddings were associated with the eventual journal at which the work was published.
We trained two machine learning models to identify which journals publish similar papers towards a query preprint.
Our models achieved modest results, which proposes that future models should include more information than solely textual content when identifying which journal venues are appropriate for a preprint.
Nevertheless, we constructed a web application that makes our models available to the public and returns a list of the papers and journals that are most similar to a bioRxiv or medRxiv preprint.
